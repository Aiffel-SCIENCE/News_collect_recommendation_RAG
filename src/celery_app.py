# src/celery_app.py
from datetime import datetime
import os
import sys
from celery import Celery
from celery.signals import worker_process_shutdown
from celery.schedules import crontab # Celery Beat ìŠ¤ì¼€ì¤„ì„ ìœ„í•´ ì¶”ê°€
import json
import traceback

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
_current_file_path = os.path.abspath(__file__)
_project_root = os.path.dirname(os.path.dirname(_current_file_path))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)
print(f"[{datetime.now()}] Project root configured: {_project_root}")

# SETTINGS ì„í¬íŠ¸ ì¶”ê°€
from src.config_loader.settings import SETTINGS

# news_collector ëª¨ë“ˆ ì„í¬íŠ¸ ì œê±° (ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
# try:
#     from src.news_collector import news_collector
#     print(f"[{datetime.now()}] news_collector module imported successfully.")
# except ImportError as e:
#     print(f"[{datetime.now()}] ERROR: Failed to import news_collector module: {e}")
#     sys.exit(1) # ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ

# pipeline_stages ëª¨ë“ˆ import (Celery task ë“±ë¡ì„ ìœ„í•´)
# ì´ ë¶€ë¶„ì€ ì‚­ì œ - initial_checks.pyì—ì„œ ì§ì ‘ íƒœìŠ¤í¬ë¥¼ ì •ì˜í•˜ë¯€ë¡œ ë¶ˆí•„ìš”

# í•„ìš”í•œ í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ ì„í¬íŠ¸ (ê¸°ì¡´ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)
from pymongo import MongoClient
import certifi
from src.db.vector_db import PineconeDB
from openai import OpenAI

print(f"[{datetime.now()}] All top-level imports in celery_app.py have been completed.")

# --- ì „ì—­ ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ---
worker_resources = {}
initialization_errors = []

print(f"[{datetime.now()}] Attempting GLOBAL (module-level) resource initialization.")

try:
    # MongoDB ì´ˆê¸°í™”
    # SETTINGSì—ì„œ MONGO_URIë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    mongo_uri = SETTINGS.get('MONGO_URI')
    if not mongo_uri:
        raise ValueError("MONGO_URI not set in config.yaml or environment variables.")
    
    # SSL/TLS ì„¤ì •ì€ MongoDB URIì— í¬í•¨ë  ìˆ˜ë„ ìˆê³ , certifiê°€ ì‚¬ìš©ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” certifië¥¼ ì‚¬ìš©í•˜ì—¬ CA ì¸ì¦ì„œë¥¼ ì§€ì •í•˜ëŠ” ì¼ë°˜ì ì¸ ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    mongo_client = MongoClient(mongo_uri, tlsCAFile=certifi.where())
    # MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ (í•„ìš”í•œ ê²½ìš°)
    mongo_client.admin.command('ping') 
    worker_resources['mongo_client'] = mongo_client
    
    # MongoDB ì»¬ë ‰ì…˜ë“¤ ì´ˆê¸°í™”
    mongo_db_name = SETTINGS.get('MONGO_DB_NAME', 'newsdb')
    mongo_articles_collection_name = SETTINGS.get('MONGO_ARTICLES_COLLECTION_NAME', 'articles')
    mongo_blacklist_collection_name = SETTINGS.get('MONGO_BLACKLIST_COLLECTION_NAME', 'Filter3')
    
    mongo_db = mongo_client[mongo_db_name]
    articles_collection = mongo_db[mongo_articles_collection_name]
    blacklist_collection = mongo_db[mongo_blacklist_collection_name]
    
    worker_resources['articles_collection'] = articles_collection
    worker_resources['blacklist_collection'] = blacklist_collection
    
    print(f"[{datetime.now()}] MongoDB client initialized successfully.")
    print(f"[{datetime.now()}] MongoDB collections initialized: {mongo_articles_collection_name}, {mongo_blacklist_collection_name}")

    # PineconeDB ì´ˆê¸°í™”
    # SETTINGSì—ì„œ Pinecone ì„¤ì •ì„ ì½ì–´ì˜µë‹ˆë‹¤.
    pinecone_api_key = SETTINGS.get('PINECONE_API_KEY')
    pinecone_environment = SETTINGS.get('PINECONE_ENVIRONMENT', 'us-east-1')
    pinecone_index_name = SETTINGS.get('PINECONE_INDEX_NAME', 'news-embedding-3')
    
    if not pinecone_api_key:
        raise ValueError("PINECONE_API_KEY not set in config.yaml or environment variables.")

    pinecone_db = PineconeDB()
    worker_resources['pinecone_manager'] = pinecone_db
    print(f"[{datetime.now()}] PineconeDB client initialized successfully.")

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    # SETTINGSì—ì„œ OPENAI_API_KEYë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    openai_api_key = SETTINGS.get('OPENAI_API_KEY')
    if not openai_api_key:
        raise ValueError("OPENAI_API_KEY not set in config.yaml or environment variables.")
    
    openai_client = OpenAI(api_key=openai_api_key)
    worker_resources['openai_client'] = openai_client
    print(f"[{datetime.now()}] OpenAI client initialized successfully.")

    # ë‹¤ë¥¸ API í‚¤ë“¤ë„ SETTINGSì—ì„œ ê°€ì ¸ì™€ì„œ í•„ìš”í•œ ê³³ì— ì „ë‹¬í•˜ê±°ë‚˜ ì „ì—­ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    worker_resources['DART_API_KEY'] = SETTINGS.get('DART_API_KEY')
    worker_resources['NAVER_CLIENT_ID'] = SETTINGS.get('NAVER_CLIENT_ID')
    worker_resources['NAVER_CLIENT_SECRET'] = SETTINGS.get('NAVER_CLIENT_SECRET')
    
    # ëª¨ë¸ëª…ë“¤ ì¶”ê°€
    worker_resources['embedding_model_name'] = SETTINGS.get('SHARED_EMBEDDING_MODEL_NAME', 'text-embedding-3-small')

except Exception as e:
    initialization_errors.append(f"Global resource initialization failed: {e}\n{traceback.format_exc()}")
    print(f"[{datetime.now()}] CRITICAL ERROR during global resource initialization: {e}")
    print(traceback.format_exc()) # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥

# Celery ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# SETTINGSì—ì„œ CELERY_BROKER_URLê³¼ CELERY_RESULT_BACKENDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
app = Celery('aigen_science',
             broker=SETTINGS.get('CELERY_BROKER_URL', 'redis://redis:6379/0'),
             backend=SETTINGS.get('CELERY_RESULT_BACKEND', 'redis://redis:6379/0'))

# Celery Beat ìŠ¤ì¼€ì¤„ ì„¤ì • (ì—¬ê¸°ê°€ í•µì‹¬ ë³€ê²½ ì‚¬í•­ ì¤‘ í•˜ë‚˜)
app.conf.beat_schedule = {
    'run-news-collector-every-hour': {
        'task': 'src.celery_app.collect_news_task', # ì•„ë˜ì— ì •ì˜í•  íƒœìŠ¤í¬ì˜ ì´ë¦„
        'schedule': crontab(minute=0, hour='0,12'),
        'args': (), # íƒœìŠ¤í¬ì— ì „ë‹¬í•  ì¸ìˆ˜ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì— íŠœí”Œë¡œ ë„£ìŠµë‹ˆë‹¤.
        'options': {'queue': 'default'} # í•„ìš”ì— ë”°ë¼ í ì§€ì •
    },
    # ì—¬ê¸°ì— ë‹¤ë¥¸ ì£¼ê¸°ì ì¸ Celery Beat íƒœìŠ¤í¬ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
}
app.conf.timezone = 'Asia/Seoul' # ì‹œê°„ëŒ€ ì„¤ì • (í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë§¤ ì‹œê°„ 0ë¶„)
print(f"[{datetime.now()}] Celery app configured with Beat schedule. Timezone: {app.conf.timezone}")

# Celery ì•± ì¸ìŠ¤í„´ìŠ¤ë¥¼ celery_appìœ¼ë¡œë„ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ë³„ì¹­ ì¶”ê°€
celery_app = app

# initial_checks ëª¨ë“ˆ import (íƒœìŠ¤í¬ ë“±ë¡ì„ ìœ„í•´)
import src.pipeline_stages.initial_checks
import src.pipeline_stages.initial_checks
import src.pipeline_stages.content_extraction
import src.pipeline_stages.categorization
import src.pipeline_stages.content_analysis
import src.pipeline_stages.embedding_generator
import src.pipeline_stages.finalization
# --- Celery íƒœìŠ¤í¬ ì •ì˜ ---

# ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬ (news_collector.pyì˜ main í•¨ìˆ˜ í˜¸ì¶œ)
@app.task
def collect_news_task():
    """
    ì£¼ê¸°ì ìœ¼ë¡œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” Celery íƒœìŠ¤í¬.
    news_collector.pyì˜ main í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    if initialization_errors:
        print(f"[{datetime.now()}] ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬: ì „ì—­ ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜ë¡œ ì¸í•´ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        for error in initialization_errors:
            print(error)
        return
        
    print(f"[{datetime.now()}] ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì‹œì‘...")
    try:
        # Lazy importë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
        from src.news_collector import news_collector
        # news_collector.pyì˜ main í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        # news_collector.main() í•¨ìˆ˜ê°€ ì œëŒ€ë¡œ ì •ì˜ë˜ì–´ ìˆê³ ,
        # ì´ í•¨ìˆ˜ ë‚´ì—ì„œ í•„ìš”í•œ ëª¨ë“  í™˜ê²½ ë³€ìˆ˜(DART, NAVER ë“±)ë¥¼ SETTINGSì—ì„œ ì½ë„ë¡ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        news_collector.collect_all_data() 
        print(f"[{datetime.now()}] ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì™„ë£Œ.")
    except Exception as e:
        print(f"[{datetime.now()}] ERROR: ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥

# PDF ì²˜ë¦¬ íƒœìŠ¤í¬ (ì˜ˆì‹œ)
@app.task
def process_pdf_task(file_path):
    """
    PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” Celery íƒœìŠ¤í¬ (ì˜ˆì‹œ).
    """
    if initialization_errors:
        print(f"[{datetime.now()}] PDF ì²˜ë¦¬ íƒœìŠ¤í¬: ì „ì—­ ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜ë¡œ ì¸í•´ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        for error in initialization_errors:
            print(error)
        return

    print(f"[{datetime.now()}] PDF ì²˜ë¦¬ íƒœìŠ¤í¬ ì‹œì‘: {file_path}")
    try:
        # ì—¬ê¸°ì— PDF ì²˜ë¦¬ ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
        # í•„ìš”í•œ ë¦¬ì†ŒìŠ¤(ì˜ˆ: worker_resources['openai_client'])ë¥¼ ì—¬ê¸°ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # ì˜ˆ: result = some_pdf_processing_function(file_path, openai_client=worker_resources['openai_client'])
        print(f"[{datetime.now()}] PDF ì²˜ë¦¬ íƒœìŠ¤í¬ ì™„ë£Œ: {file_path}")
        return {"status": "success", "file": file_path}
    except Exception as e:
        print(f"[{datetime.now()}] ERROR: PDF ì²˜ë¦¬ íƒœìŠ¤í¬ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc())
        return {"status": "failed", "file": file_path, "error": str(e)}

# Celery Worker í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
@worker_process_shutdown.connect
def cleanup_worker_resources(sender=None, **kwargs):
    print(f"[{datetime.now()}] Celery worker shutting down. Cleaning up resources...")
    if 'mongo_client' in worker_resources and worker_resources['mongo_client']:
        worker_resources['mongo_client'].close()
        print(f"[{datetime.now()}] MongoDB client closed.")
    # PineconeDBëŠ” ëª…ì‹œì ì¸ close ë©”ì„œë“œê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # í•„ìš”í•œ ë‹¤ë¥¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë¡œì§ì„ ì—¬ê¸°ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    print(f"[{datetime.now()}] Resource cleanup complete.")

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´) ---

# ì´ í•¨ìˆ˜ëŠ” Celery íƒœìŠ¤í¬ ë‚´ì—ì„œ ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì„ ìˆ˜ ìˆì§€ë§Œ,
# í”„ë¡œì íŠ¸ì˜ ë‹¤ë¥¸ ë¶€ë¶„ì—ì„œ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
def save_to_data_folder(article_data, stage_name_path, status_prefix="processed"):
    return # ì´ í•¨ìˆ˜ëŠ” í˜„ì¬ returnìœ¼ë¡œ ë°”ë¡œ ì¢…ë£Œë˜ë¯€ë¡œ ì‹¤ì œ ì €ì¥ ê¸°ëŠ¥ì€ ì—†ìŠµë‹ˆë‹¤.
    log_dir_base = os.path.join(_project_root, "data", "celery_pipeline_logs")
    log_dir_stage = os.path.join(log_dir_base, stage_name_path)
    os.makedirs(log_dir_stage, exist_ok=True)

    filename_safe_title = "".join(c if c.isalnum() else "_" for c in article_data.get("title", "no_title"))[:50]
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")
    unique_id_part = article_data.get("id", "no_id")
    if unique_id_part == "no_id" and article_data.get("url"):
        unique_id_part = "".join(c if c.isalnum() else "_" for c in article_data.get("url"))[-20:]

    filename = f"{status_prefix}_{filename_safe_title}_{timestamp}_{unique_id_part}.json"
    filepath = os.path.join(log_dir_stage, filename)
    
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            # MongoDB ObjectIdì™€ ê°™ì€ ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ë“¤ì„ ì²˜ë¦¬
            def convert_sets_to_lists(obj):
                if isinstance(obj, set):
                    return list(obj)
                elif isinstance(obj, dict):
                    return {k: convert_sets_to_lists(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_sets_to_lists(item) for item in obj]
                else:
                    return obj
            
            converted_data = convert_sets_to_lists(article_data)
            json.dump(converted_data, f, ensure_ascii=False, indent=2, default=str)
        print(f"  ğŸ“ Celery Pipeline Log: {filepath}")
        return filepath
    except Exception as e:
        print(f"  âŒ Celery Pipeline Log ì €ì¥ ì‹¤íŒ¨: {e}")
        return None
