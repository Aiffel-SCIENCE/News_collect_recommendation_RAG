# src/pipeline_stages/embedding_generator.py

from celery import shared_task
from typing import Tuple, List
from src.pipeline_stages.finalization import finalization_task
import time
from openai import RateLimitError

def _generate_single_embedding(text: str, openai_client, model_name: str) -> list:
    if not openai_client:
        print("EmbeddingGenerator Task Error: OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    if not text or not text.strip():
        print("EmbeddingGenerator Task Info: ë¹„ì–´ìˆê±°ë‚˜ ê³µë°±ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ì„ë² ë”©ì„ ê±´ë„ˆëœ€.")
        return []
    
    max_retries = 3
    base_delay = 2  # ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    
    for attempt in range(max_retries):
        try:
            response = openai_client.embeddings.create(
                model=model_name,
                input=text
            )
            embedding_vector = response.data[0].embedding
            return embedding_vector
            
        except RateLimitError as e:
            if attempt < max_retries - 1:
                wait_time = base_delay * (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                print(f"Embedding rate limit reached, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                time.sleep(wait_time)
                continue
            else:
                print(f"Embedding rate limit error after {max_retries} attempts: {e}")
                return []
                
        except Exception as e:
            print(f"EmbeddingGenerator Task Error: í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"ì˜¤ë¥˜ ë°œìƒ í…ìŠ¤íŠ¸ (ì• 100ì): {text[:100]}...")
            if attempt < max_retries - 1:
                wait_time = base_delay * (2 ** attempt)
                print(f"Embedding error, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                time.sleep(wait_time)
                continue
            else:
                return []
    
    return []


@shared_task(bind=True, max_retries=2, default_retry_delay=60)
def embedding_generation_task(self, article_data: dict):
    task_id_log = f"(Task ID: {self.request.id})" if self.request.id else ""
    print(f"\nğŸ“° Embedding Generation Task: ì²˜ë¦¬ ì‹œì‘ {task_id_log} - {article_data.get('url', 'URL ì—†ìŒ')[:70]}...")
    current_stage_name_path = "stage5_embedding_celery"
    
    # í•„ìš”í•  ë•Œë§Œ ê°€ì ¸ì˜¤ê¸°
    import src.celery_app
    worker_resources = src.celery_app.worker_resources
    save_to_data_folder = src.celery_app.save_to_data_folder
    
    openai_client = worker_resources.get('openai_client')
    embedding_model_name = worker_resources.get('embedding_model_name', 'text-embedding-3-small')

    if openai_client is None:
        error_msg = "OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì•ˆë¨."
        print(f"âŒ Embedding Generation Task CRITICAL: {error_msg} {task_id_log}")
        article_data["embedding"] = []
        article_data["llm_internal_keywords_embedding"] = []
        article_data.setdefault("checked", {})["embedding_generation_reason"] = "OPENAI_CLIENT_NOT_INITIALIZED_CELERY"
        save_to_data_folder(article_data, f"{current_stage_name_path}/failed_or_skipped", "skipped_model_error")
        raise Exception(f"OpenAI Client Uninitialized: {error_msg}")

    # 1. ì½˜í…ì¸  ì„ë² ë”© ìƒì„±
    title_for_embedding = article_data.get("title", "")
    content_for_embedding = article_data.get("content", "")
    text_to_embed = f"{title_for_embedding}\n{content_for_embedding}".strip()

    embedded = False
    if not text_to_embed:
        article_data["embedding"] = []
        article_data.setdefault("checked", {})["embedding_generation_reason"] = "NO_TEXT_TO_EMBED_CELERY"
    else:
        try:
            embedding_vector = _generate_single_embedding(text_to_embed, openai_client, embedding_model_name)
            article_data["embedding"] = embedding_vector
            if embedding_vector:
                embedded = True
            else:
                article_data.setdefault("checked", {})["embedding_generation_reason"] = "EMBEDDING_FAILED_EMPTY_VECTOR_CELERY"
        except Exception as e_embed:
            print(f"Embedding Generation Task Error during _generate_single_embedding (content): {e_embed} {task_id_log}")
            article_data["embedding"] = []
            article_data.setdefault("checked", {})["embedding_generation_reason"] = f"CONTENT_EMBEDDING_EXCEPTION: {str(e_embed)[:100]}"
            raise self.retry(exc=e_embed)

    # 2. LLM í‚¤ì›Œë“œ ì„ë² ë”© ìƒì„± 
    keywords = article_data.get("llm_internal_keywords", [])
    individual_keyword_embeddings = [] # ê°œë³„ ì„ë² ë”©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    if keywords and openai_client:
        print(f"  âœ¨ Stage 5 (Embedding Generation Task): LLM í‚¤ì›Œë“œ {len(keywords)}ê°œ ê°œë³„ ì„ë² ë”© ì‹œì‘...")
        for keyword in keywords:
            try:
                # ê° í‚¤ì›Œë“œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì„ë² ë”©
                kw_embedding_vector = _generate_single_embedding(keyword, openai_client, embedding_model_name)
                if kw_embedding_vector:
                    individual_keyword_embeddings.append(kw_embedding_vector)
            except Exception as e_kw_embed:
                print(f"  âš ï¸ Stage 5 (Embedding Generation Task): í‚¤ì›Œë“œ '{keyword}' ì„ë² ë”© ì¤‘ ì˜¤ë¥˜: {e_kw_embed}")
        
        # ìƒˆë¡œ ìƒì„±ëœ ê°œë³„ í‚¤ì›Œë“œ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥
        article_data["llm_individual_keyword_embeddings"] = individual_keyword_embeddings
        # ê¸°ì¡´ í•„ë“œëŠ” ì œê±°í•˜ê±°ë‚˜ ë¹„ì›Œë‘ 
        article_data["llm_internal_keywords_embedding"] = [] 
        
        if individual_keyword_embeddings:
            print(f"  âœ… Stage 5 (Embedding Generation Task): LLM í‚¤ì›Œë“œ ê°œë³„ ì„ë² ë”© ìƒì„± ì™„ë£Œ. (ì„±ê³µ: {len(individual_keyword_embeddings)}ê°œ)")
    else:
        # í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°, í•„ë“œë¥¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
        article_data["llm_individual_keyword_embeddings"] = []
        article_data["llm_internal_keywords_embedding"] = []

    article_data.setdefault("checked", {})["embedding_generation"] = embedded
    if not embedded:
        print(f"  âš ï¸ Stage 5 (Embedding Generation Task): ì½˜í…ì¸  ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ê±´ë„ˆëœ€. ê¸°ì‚¬: {article_data.get('url')} {task_id_log}")
        save_to_data_folder(article_data, f"{current_stage_name_path}/failed_or_skipped", "skipped")
    else:
        print(f"  âœ… Stage 5 (Embedding Generation Task): ì½˜í…ì¸  ì„ë² ë”© ì„±ê³µ. ê¸°ì‚¬: {article_data.get('url')} {task_id_log}")
        save_to_data_folder(article_data, f"{current_stage_name_path}/passed", "passed")

    finalization_task.delay(article_data)
    return {"article_id": article_data.get("ID"), "embedded": embedded}
